{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "To do any computation, you need to have data. Getting the data in the framework of a workflow is therefore the first step of every analysis. Nipype provides many different modules to grab or select the data:\n",
    "\n",
    "    DataFinder\n",
    "    DataGrabber\n",
    "    FreeSurferSource\n",
    "    JSONFileGrabber\n",
    "    S3DataGrabber\n",
    "    SSHDataGrabber\n",
    "    SelectFiles\n",
    "    XNATSource\n",
    "\n",
    "This tutorial will only cover some of them. For the rest, see the section [``interfaces.io``](https://nipype.readthedocs.io/en/latest/api/generated/nipype.interfaces.io.html) on the official homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset structure\n",
    "\n",
    "To be able to import data, you first need to be aware of the structure of your dataset. The structure of the dataset for this tutorial is according to BIDS, and looks as follows:\n",
    "\n",
    "    ds000114\n",
    "    ├── CHANGES\n",
    "    ├── dataset_description.json\n",
    "    ├── derivatives\n",
    "    │   ├── fmriprep\n",
    "    │   │   └── sub01...sub10\n",
    "    │   │        └── ...\n",
    "    │   ├── freesurfer\n",
    "    │       ├── fsaverage\n",
    "    │       ├── fsaverage5\n",
    "    │   │   └── sub01...sub10\n",
    "    │   │        └── ...\n",
    "    ├── dwi.bval\n",
    "    ├── dwi.bvec\n",
    "    ├── sub-01\n",
    "    │   ├── ses-retest    \n",
    "    │       ├── anat\n",
    "    │       │   └── sub-01_ses-retest_T1w.nii.gz\n",
    "    │       ├──func\n",
    "    │           ├── sub-01_ses-retest_task-covertverbgeneration_bold.nii.gz\n",
    "    │           ├── sub-01_ses-retest_task-fingerfootlips_bold.nii.gz\n",
    "    │           ├── sub-01_ses-retest_task-linebisection_bold.nii.gz\n",
    "    │           ├── sub-01_ses-retest_task-linebisection_events.tsv\n",
    "    │           ├── sub-01_ses-retest_task-overtverbgeneration_bold.nii.gz\n",
    "    │           └── sub-01_ses-retest_task-overtwordrepetition_bold.nii.gz\n",
    "    │       └── dwi\n",
    "    │           └── sub-01_ses-retest_dwi.nii.gz\n",
    "    │   ├── ses-test    \n",
    "    │       ├── anat\n",
    "    │       │   └── sub-01_ses-test_T1w.nii.gz\n",
    "    │       ├──func\n",
    "    │           ├── sub-01_ses-test_task-covertverbgeneration_bold.nii.gz\n",
    "    │           ├── sub-01_ses-test_task-fingerfootlips_bold.nii.gz\n",
    "    │           ├── sub-01_ses-test_task-linebisection_bold.nii.gz\n",
    "    │           ├── sub-01_ses-test_task-linebisection_events.tsv\n",
    "    │           ├── sub-01_ses-test_task-overtverbgeneration_bold.nii.gz\n",
    "    │           └── sub-01_ses-test_task-overtwordrepetition_bold.nii.gz\n",
    "    │       └── dwi\n",
    "    │           └── sub-01_ses-retest_dwi.nii.gz\n",
    "    ├── sub-02..sub-10\n",
    "    │   └── ...\n",
    "    ├── task-covertverbgeneration_bold.json\n",
    "    ├── task-covertverbgeneration_events.tsv\n",
    "    ├── task-fingerfootlips_bold.json\n",
    "    ├── task-fingerfootlips_events.tsv\n",
    "    ├── task-linebisection_bold.json\n",
    "    ├── task-overtverbgeneration_bold.json\n",
    "    ├── task-overtverbgeneration_events.tsv\n",
    "    ├── task-overtwordrepetition_bold.json\n",
    "    └── task-overtwordrepetition_events.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataGrabber\n",
    "\n",
    "`DataGrabber` is an interface for collecting files from hard drive. It is very flexible and supports almost any file organization of your data you can imagine.\n",
    "\n",
    "You can use it as a trivial use case of getting a fixed file. By default, `DataGrabber` stores its outputs in a field called outfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio\n",
    "datasource1 = nio.DataGrabber()\n",
    "datasource1.inputs.base_directory = '/data/ds000114'\n",
    "datasource1.inputs.template = 'sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz'\n",
    "datasource1.inputs.sort_filelist = True\n",
    "results = datasource1.run()\n",
    "results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can get at all NIfTI files containing the word `'fingerfootlips'` in all directories starting with the letter `'s'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio\n",
    "datasource2 = nio.DataGrabber()\n",
    "datasource2.inputs.base_directory = '/data/ds000114'\n",
    "datasource2.inputs.template = 's*/ses-test/func/*fingerfootlips*.nii.gz'\n",
    "datasource2.inputs.sort_filelist = True\n",
    "results = datasource2.run()\n",
    "results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two special inputs were used in these previous cases. The input `base_directory`\n",
    "indicates in which directory to search, while the input `template` indicates the\n",
    "string template to match. So in the previous case `DataGrabber` is looking for\n",
    "path matches of the form `/data/ds000114/s*/ses-test/func/*fingerfootlips*.nii.gz`.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Note**: When used with wildcards (e.g., `s*` and `*fingerfootlips*` above) `DataGrabber` does not return data in sorted order. In order to force it to return data in a sorted order, one needs to set the input `sorted = True`. However, when explicitly specifying an order as we will see below, `sorted` should be set to `False`.\n",
    "</div>\n",
    "\n",
    "More use cases arise when the template can be filled by other inputs. In the\n",
    "example below, we define an input field for `DataGrabber` called `subject_id`. This is\n",
    "then used to set the template (see `%d` in the template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource3 = nio.DataGrabber(infields=['subject_id'])\n",
    "datasource3.inputs.base_directory = '/data/ds000114'\n",
    "datasource3.inputs.template = 'sub-%02d/ses-test/func/*fingerfootlips*.nii.gz'\n",
    "datasource3.inputs.sort_filelist = True\n",
    "datasource3.inputs.subject_id = [1, 7]\n",
    "results = datasource3.run()\n",
    "results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the functional images from subject 1 and 7 for the task `fingerfootlips`. We can take this a step further and pair subjects with task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource4 = nio.DataGrabber(infields=['subject_id', 'run'])\n",
    "datasource4.inputs.base_directory = '/data/ds000114'\n",
    "datasource4.inputs.template = 'sub-%02d/ses-test/func/*%s*.nii.gz'\n",
    "datasource4.inputs.sort_filelist = True\n",
    "datasource4.inputs.run = ['fingerfootlips', 'linebisection']\n",
    "datasource4.inputs.subject_id = [1, 7]\n",
    "results = datasource4.run()\n",
    "results.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the functional image of subject 1, task `'fingerfootlips'` and the functional image of subject 7 for the `'linebisection'` task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more realistic use-case\n",
    "\n",
    "``DataGrabber`` is a generic data grabber module that wraps around ``glob`` to select your neuroimaging data in an intelligent way. As an example, let's assume we want to grab the anatomical and functional images of a certain subject.\n",
    "\n",
    "First, we need to create the ``DataGrabber`` node. This node needs to have some input fields for all dynamic parameters (e.g. subject identifier, task identifier), as well as the two desired output fields ``anat`` and ``func``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import DataGrabber, Node\n",
    "\n",
    "# Create DataGrabber node\n",
    "dg = Node(DataGrabber(infields=['subject_id', 'ses_name', 'task_name'],\n",
    "                      outfields=['anat', 'func']),\n",
    "          name='datagrabber')\n",
    "\n",
    "# Location of the dataset folder\n",
    "dg.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Necessary default parameters\n",
    "dg.inputs.template = '*'\n",
    "dg.inputs.sort_filelist = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we know that the two files we desire are the the following location:\n",
    "\n",
    "    anat = /data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz\n",
    "\n",
    "We see that the two files only have three dynamic parameters between subjects and task names:\n",
    "\n",
    "    subject_id: in this case 'sub-01'\n",
    "    task_name: in this case fingerfootlips\n",
    "    ses_name: test\n",
    "\n",
    "This means that we can rewrite the paths as follows:\n",
    "\n",
    "    anat = /data/ds102/[subject_id]/ses-[ses_name]/anat/sub-[subject_id]_ses-[ses_name]_T1w.nii.gz\n",
    "    func = /data/ds102/[subject_id]/ses-[ses_name]/func/sub-[subject_id]_ses-[ses_name]_task-[task_name]_bold.nii.gz\n",
    "\n",
    "Therefore, we need the parameters ``subject_id`` and ``ses_name`` for the anatomical image and the parameters ``subject_id``, ``ses_name`` and ``task_name`` for the functional image. In the context of DataGabber, this is specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.inputs.template_args = {'anat': [['subject_id', 'ses_name']],\n",
    "                           'func': [['subject_id', 'ses_name', 'task_name']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comes the most important part of DataGrabber. We need to specify the template structure to find the specific data. This can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.inputs.field_template = {'anat': 'sub-%02d/ses-%s/anat/*_T1w.nii.gz',\n",
    "                            'func': 'sub-%02d/ses-%s/func/*task-%s_bold.nii.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that we use ``%s``, ``%02d`` and ``*`` for placeholders in the data paths. ``%s`` is a placeholder for a string and is filled out by ``task_name`` or ``ses_name``. ``%02d`` is a placeholder for a integer number and is filled out by ``subject_id``. ``*`` is used as a wild card, e.g. a placeholder for any possible string combination. This is all to set up the ``DataGrabber`` node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, two more fields are introduced: `field_template` and `template_args`. These fields are both dictionaries whose keys correspond to the `outfields` keyword. The `field_template` reflects the search path for each output field, while the `template_args` reflect the inputs that satisfy the template. The inputs can either be one of the named inputs specified by the `infields` keyword arg or it can be raw strings or integers corresponding to the template. For the `func` output, the **%s** in the `field_template` is satisfied by `subject_id` and the **%d** is filled in by the list of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is up to you how you want to feed the dynamic parameters into the node. You can either do this by using another node (e.g. ``IdentityInterface``) and feed ``subject_id``, ``ses_name`` and ``task_name`` as connections to the ``DataGrabber`` node or specify them directly as node inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the IdentityInterface\n",
    "from nipype import IdentityInterface\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'task_name']),\n",
    "                  name=\"infosource\")\n",
    "infosource.inputs.task_name = \"fingerfootlips\"\n",
    "infosource.inputs.ses_name = \"test\"\n",
    "subject_id_list = [1, 2]\n",
    "infosource.iterables = [('subject_id', subject_id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you only have to connect ``infosource`` with your ``DataGrabber`` and run the workflow to iterate over subjects 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also provide the inputs to the ``DataGrabber`` node directly, for one subject you can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the input fields of DataGrabber directly\n",
    "dg.inputs.subject_id = 1\n",
    "dg.inputs.ses_name = \"test\"\n",
    "dg.inputs.task_name = \"fingerfootlips\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the ``DataGrabber`` node and let's look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Grab T1w images from both sessions - ``ses-test`` and ``ses-retest`` for ``sub-01``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from nipype import DataGrabber, Node\n",
    "\n",
    "# Create DataGrabber node\n",
    "ex1_dg = Node(DataGrabber(infields=['subject_id', 'ses_name'],\n",
    "                      outfields=['anat']),\n",
    "          name='datagrabber')\n",
    "\n",
    "# Location of the dataset folder\n",
    "ex1_dg.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Necessary default parameters\n",
    "ex1_dg.inputs.template = '*'\n",
    "ex1_dg.inputs.sort_filelist = True\n",
    "\n",
    "# specify the template\n",
    "ex1_dg.inputs.template_args = {'anat': [['subject_id', 'ses_name']]}\n",
    "ex1_dg.inputs.field_template = {'anat': 'sub-%02d/ses-%s/anat/*_T1w.nii.gz'}\n",
    "\n",
    "# specify subject_id and ses_name you're interested in\n",
    "ex1_dg.inputs.subject_id = 1\n",
    "ex1_dg.inputs.ses_name = [\"test\", \"retest\"]\n",
    "\n",
    "# and run the node\n",
    "ex1_res = ex1_dg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# you can now check the output\n",
    "ex1_res.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectFiles\n",
    "\n",
    "`SelectFiles` is a more flexible alternative to `DataGrabber`. It is built on Python [format strings](http://docs.python.org/2/library/string.html#format-string-syntax), which are similar to the Python string interpolation feature you are likely already familiar with, but advantageous in several respects. Format strings allow you to replace named sections of template strings set off by curly braces (`{}`), possibly filtered through a set of functions that control how the values are rendered into the string. As a very basic example, we could write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"This workflow uses {package}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then format it with keyword arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msg.format(package=\"FSL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SelectFiles` uses the {}-based string formatting syntax to plug values into string templates and collect the data. These templates can also be combined with glob wild cards. The field names in the formatting template (i.e. the terms in braces) will become inputs fields on the interface, and the keys in the templates dictionary will form the output fields.\n",
    "\n",
    "Let's focus again on the data we want to import:\n",
    "\n",
    "    anat = /data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz\n",
    "    \n",
    "Now, we can replace those paths with the according {}-based strings.\n",
    "\n",
    "    anat = /data/ds000114/sub-{subject_id}/ses-{ses_name}/anat/sub-{subject_id}_ses-{ses_name}_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-{subject_id}/ses-{ses_name}/func/ \\\n",
    "            sub-{subject_id}_ses-{ses_name}_task-{task_name}_bold.nii.gz\n",
    "\n",
    "How would this look like as a `SelectFiles` node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-{subject_id}/ses-{ses_name}/anat/sub-{subject_id}_ses-{ses_name}_T1w.nii.gz',\n",
    "             'func': 'sub-{subject_id}/ses-{ses_name}/func/sub-{subject_id}_ses-{ses_name}_task-{task_name}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Feed {}-based placeholder strings with values\n",
    "sf.inputs.subject_id = '01'\n",
    "sf.inputs.ses_name = \"test\"\n",
    "sf.inputs.task_name = 'fingerfootlips'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we get what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! But why is `SelectFiles` more flexible than `DataGrabber`? First, you perhaps noticed that with the {}-based string, we can reuse the same input (e.g. `subject_id`) multiple time in the same string, without feeding it multiple times into the template.\n",
    "\n",
    "Additionally, you can also select multiple files without the need of an iterable node. For example, let's assume we want to select anatomical images for all subjects at once. We can do this by using the eildcard ``*`` in a template:\n",
    "\n",
    "    'sub-*/anat/sub-*_T1w.nii.gz'\n",
    "\n",
    "Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-*/ses-{ses_name}/anat/sub-*_ses-{ses_name}_T1w.nii.gz'}\n",
    "\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Feed {}-based placeholder strings with values\n",
    "sf.inputs.ses_name = 'test'\n",
    "\n",
    "# Print SelectFiles output\n",
    "sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, now `anat` contains ten file paths, T1w images for all ten subject. \n",
    "\n",
    "As a side note, you could also use ``[]`` string formatting for some simple cases, e.g. for loading only subject 1 and 2: \n",
    "\n",
    "    'sub-0[1,2]/ses-test/anat/sub-0[1,2]_ses-test_T1w.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `force_lists`\n",
    "\n",
    "There's an additional parameter, `force_lists`, which controls how `SelectFiles` behaves in cases where only a single file matches the template. The default behavior is that when a template matches multiple files they are returned as a list, while a single file is returned as a string. There may be situations where you want to force the outputs to always be returned as a list (for example, you are writing a workflow that expects to operate on several runs of data, but some of your subjects only have a single run). In this case, `force_lists` can be used to tune the outputs of the interface. You can either use a boolean value, which will be applied to every output the interface has, or you can provide a list of the output fields that should be coerced to a list.\n",
    "\n",
    "Returning to our previous example, you may want to ensure that the `anat` files are returned as a list, but you only ever will have a single `T1` file. In this case, you would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SelectFiles(templates, force_lists=[\"anat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Use ``SelectFile`` to select again T1w images from both sessions - ``ses-test`` and ``ses-retest`` for ``sub-01``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-01/ses-*/anat/sub-01_ses-*_T1w.nii.gz'}\n",
    "             \n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "#sf.inputs.ses_name = \n",
    "\n",
    "sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FreeSurferSource\n",
    "\n",
    "`FreeSurferSource` is a specific case of a file grabber that facilitates the data import of outputs from the FreeSurfer recon-all algorithm. This, of course, requires that you've already run `recon-all` on your subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tutorial dataset ``ds000114``, `recon-all` was already run. So, let's make sure that you have the anatomy output of one subject on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad get -r -J 4 -d /data/ds000114 /data/ds000114/derivatives/freesurfer/sub-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before you can run `FreeSurferSource`, you first have to specify the path to the FreeSurfer output folder, i.e. you have to specify the SUBJECTS_DIR variable. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer import FSCommand\n",
    "from os.path import abspath as opap\n",
    "\n",
    "# Path to your freesurfer output folder\n",
    "fs_dir = opap('/data/ds000114/derivatives/freesurfer/')\n",
    "\n",
    "# Set SUBJECTS_DIR\n",
    "FSCommand.set_default_subjects_dir(fs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the `FreeSurferSource` node, do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Node\n",
    "from nipype.interfaces.io import FreeSurferSource\n",
    "\n",
    "# Create FreeSurferSource node\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                name='fssource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run it for a specific subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fssource.inputs.subject_id = 'sub-01'\n",
    "result = fssource.run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Let's try to access multiple FreeSurfer outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('aparc_aseg: %s\\n' % result.outputs.aparc_aseg)\n",
    "print('inflated: %s\\n' % result.outputs.inflated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working as it should. But as you can see, the `inflated` output actually contains the file location for both hemispheres. With `FreeSurferSource` we can also restrict the file selection to a single hemisphere. To do this, we use the `hemi` input filed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fssource.inputs.hemi = 'lh'\n",
    "result = fssource.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look again at the `inflated` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.outputs.inflated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
