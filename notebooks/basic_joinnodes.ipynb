{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JoinNode, synchronize and itersource\n",
    "\n",
    "JoinNode has the opposite effect of [iterables](basic_iteration.ipynb). Where `iterables` split up the execution workflow into many different branches, a `JoinNode` merges them back into on node. A `JoinNode` generalizes `MapNode` to operate in conjunction with an upstream `iterable` node to reassemble downstream results, e.g.:\n",
    "\n",
    "<img src=\"../static/images/joinnode.png\"  width=\"240\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "Let's consider the very simple example depicted at the top of this page:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nipype import Node, JoinNode, Workflow\n",
    "\n",
    "# Specify fake input node A\n",
    "a = Node(interface=A(), name=\"a\")\n",
    "\n",
    "# Iterate over fake node B's input 'in_file?\n",
    "b = Node(interface=B(), name=\"b\")\n",
    "b.iterables = ('in_file', [file1, file2])\n",
    "\n",
    "# Pass results on to fake node C\n",
    "c = Node(interface=C(), name=\"c\")\n",
    "\n",
    "# Join forked execution workflow in fake node D\n",
    "d = JoinNode(interface=D(),\n",
    "             joinsource=\"b\",\n",
    "             joinfield=\"in_files\",\n",
    "             name=\"d\")\n",
    "\n",
    "# Put everything into a workflow as usual\n",
    "workflow = Workflow(name=\"workflow\")\n",
    "workflow.connect([(a, b, [('subject', 'subject')]),\n",
    "                  (b, c, [('out_file', 'in_file')])\n",
    "                  (c, d, [('out_file', 'in_files')])\n",
    "                  ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, setting up a ``JoinNode`` is rather simple. The only difference to a normal ``Node`` is the ``joinsource`` and the ``joinfield``. ``joinsource`` specifies from which node the information to join is coming and the ``joinfield`` specifies the input field of the `JoinNode` where the information to join will be entering the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes that interface `A` has one output *subject*, interface `B` has two inputs *subject* and *in_file* and one output *out_file*, interface `C` has one input *in_file* and one output *out_file*, and interface `D` has one list input *in_files*. The *images* variable is a list of three input image file names.\n",
    "\n",
    "As with *iterables* and the `MapNode` *iterfield*, the *joinfield* can be a list of fields. Thus, the declaration in the previous example is equivalent to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "d = JoinNode(interface=D(),\n",
    "             joinsource=\"b\",\n",
    "             joinfield=[\"in_files\"],\n",
    "             name=\"d\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *joinfield* defaults to all of the JoinNode input fields, so the declaration is also equivalent to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "d = JoinNode(interface=D(),\n",
    "             joinsource=\"b\",\n",
    "             name=\"d\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the node `C` *out_file* outputs are collected into the `JoinNode` `D` *in_files* input list. The *in_files* order is the same as the upstream `B` node iterables order.\n",
    "\n",
    "The `JoinNode` input can be filtered for unique values by specifying the *unique* flag, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "d = JoinNode(interface=D(),\n",
    "             joinsource=\"b\",\n",
    "             unique=True,\n",
    "             name=\"d\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `synchronize`\n",
    "\n",
    "The `Node` `iterables` parameter can be be a single field or a list of fields. If it is a list, then execution is performed over all permutations of the list items. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "b.iterables = [(\"m\", [1, 2]), (\"n\", [3, 4])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../static/images/synchronize_1.png\"  width=\"325\">\n",
    "\n",
    "where `B13` has inputs *m* = 1, *n* = 3, `B14` has inputs  *m* = 1, *n* = 4, etc.\n",
    "\n",
    "The `synchronize` parameter synchronizes the iterables lists, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "b.iterables = [(\"m\", [1, 2]), (\"n\", [3, 4])]\n",
    "b.synchronize = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../static/images/synchronize_2.png\" width=\"160\">\n",
    "\n",
    "where the iterable inputs are selected in lock-step by index, i.e.:\n",
    "\n",
    "    (*m*, *n*) = (1, 3) and (2, 4)\n",
    "\n",
    "for `B13` and `B24`, resp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `itersource`\n",
    "\n",
    "The `itersource` feature allows you to expand a downstream `iterable` based on a mapping of an upstream `iterable`. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = Node(interface=A(), name=\"a\")\n",
    "b = Node(interface=B(), name=\"b\")\n",
    "b.iterables = (\"m\", [1, 2])\n",
    "c = Node(interface=C(), name=\"c\")\n",
    "d = Node(interface=D(), name=\"d\")\n",
    "d.itersource = (\"b\", \"m\")\n",
    "d.iterables = [(\"n\", {1:[3,4], 2:[5,6]})]\n",
    "my_workflow = Workflow(name=\"my_workflow\")\n",
    "my_workflow.connect([(a,b,[('out_file','in_file')]),\n",
    "                     (b,c,[('out_file','in_file')])\n",
    "                     (c,d,[('out_file','in_file')])\n",
    "                     ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results in the execution graph:\n",
    "\n",
    "<img src=\"../static/images/itersource_1.png\" width=\"350\">\n",
    "\n",
    "In this example, all interfaces have input `in_file` and output `out_file`. In addition, interface `B` has input *m* and interface `D` has input *n*. A Python dictionary associates the `B` node input value with the downstream `D` node *n* iterable values.\n",
    "\n",
    "This example can be extended with a summary `JoinNode`:\n",
    "\n",
    "```python\n",
    "e = JoinNode(interface=E(), joinsource=\"d\",\n",
    "             joinfield=\"in_files\", name=\"e\")\n",
    "my_workflow.connect(d, 'out_file',\n",
    "                    e, 'in_files')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting in the graph:\n",
    "\n",
    "<img src=\"../static/images/itersource_2.png\" width=\"350\">\n",
    "\n",
    "The combination of `iterables`, `MapNode`, `JoinNode`, `synchronize` and `itersource` enables the creation of arbitrarily complex workflow graphs. The astute workflow builder will recognize that this flexibility is both a blessing and a curse. These advanced features are handy additions to the Nipype toolkit when used judiciously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More realistic `JoinNode` example\n",
    "\n",
    "Let's consider another example where we have one node that iterates over 3 different numbers and generates random numbers. Another node joins those three different numbers (each coming from a separate branch of the workflow) into one list. To make the whole thing a bit more realistic, the second node will use the ``Function`` interface to do something with those numbers, before we spit them out again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import JoinNode, Node, Workflow\n",
    "from nipype.interfaces.utility import Function, IdentityInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id):\n",
    "    \"\"\"Generate a random number based on id\"\"\"\n",
    "    import numpy as np\n",
    "    return id + np.random.rand()\n",
    "\n",
    "def merge_and_scale_data(data2):\n",
    "    \"\"\"Scale the input list by 1000\"\"\"\n",
    "    import numpy as np\n",
    "    return (np.array(data2) * 1000).tolist()\n",
    "\n",
    "\n",
    "node1 = Node(Function(input_names=['id'],\n",
    "                      output_names=['data1'],\n",
    "                      function=get_data_from_id),\n",
    "             name='get_data')\n",
    "node1.iterables = ('id', [1, 2, 3])\n",
    "\n",
    "node2 = JoinNode(Function(input_names=['data2'],\n",
    "                          output_names=['data_scaled'],\n",
    "                          function=merge_and_scale_data),\n",
    "                 name='scale_data',\n",
    "                 joinsource=node1,\n",
    "                 joinfield=['data2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(name='testjoin')\n",
    "wf.connect(node1, 'data1', node2, 'data2')\n",
    "eg = wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.write_graph(graph2use='exec')\n",
    "from IPython.display import Image\n",
    "Image(filename='graph_detailed.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the input and output of the joinnode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [node for node in eg.nodes() if 'scale_data' in node.name][0].result\n",
    "res.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending to multiple nodes\n",
    "\n",
    "We extend the workflow by using three nodes. Note that even this workflow, the joinsource corresponds to the node containing iterables and the joinfield corresponds to the input port of the JoinNode that aggregates the iterable branches. As before the graph below shows how the execution process is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_id(id):\n",
    "    import numpy as np\n",
    "    return id + np.random.rand()\n",
    "\n",
    "def scale_data(data2):\n",
    "    import numpy as np\n",
    "    return data2\n",
    "\n",
    "def replicate(data3, nreps=2):\n",
    "    return data3 * nreps\n",
    "\n",
    "node1 = Node(Function(input_names=['id'],\n",
    "                      output_names=['data1'],\n",
    "                      function=get_data_from_id),\n",
    "             name='get_data')\n",
    "node1.iterables = ('id', [1, 2, 3])\n",
    "\n",
    "node2 = Node(Function(input_names=['data2'],\n",
    "                      output_names=['data_scaled'],\n",
    "                      function=scale_data),\n",
    "             name='scale_data')\n",
    "\n",
    "node3 = JoinNode(Function(input_names=['data3'],\n",
    "                          output_names=['data_repeated'],\n",
    "                          function=replicate),\n",
    "                 name='replicate_data',\n",
    "                 joinsource=node1,\n",
    "                 joinfield=['data3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(name='testjoin')\n",
    "wf.connect(node1, 'data1', node2, 'data2')\n",
    "wf.connect(node2, 'data_scaled', node3, 'data3')\n",
    "eg = wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.write_graph(graph2use='exec')\n",
    "Image(filename='graph_detailed.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "You have list of DOB of the subjects in a few various format : ``[\"10 February 1984\", \"March 5 1990\", \"April 2 1782\", \"June 6, 1988\", \"12 May 1992\"]``, and you want to sort the list.\n",
    "\n",
    "You can use ``Node`` with ``iterables`` to extract day, month and year, and use [datetime.datetime](https://docs.python.org/2/library/datetime.html) to unify the format that can be compared, and ``JoinNode`` to sort the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# the list of all DOB\n",
    "dob_subjects = [\"10 February 1984\", \"March 5 1990\", \"April 2 1782\", \"June 6, 1988\", \"12 May 1992\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# let's start from creating Node with iterable to split all strings from the list\n",
    "from nipype import Node, JoinNode, Function, Workflow\n",
    "\n",
    "def split_dob(dob_string):\n",
    "    return dob_string.split()\n",
    "\n",
    "split_node = Node(Function(input_names=[\"dob_string\"], \n",
    "                              output_names=[\"split_list\"], \n",
    "                              function=split_dob),\n",
    "                    name=\"splitting\")\n",
    "\n",
    "#split_node.inputs.dob_string = \"10 February 1984\"\n",
    "split_node.iterables = (\"dob_string\", dob_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# and now let's work on the date format more, independently for every element\n",
    "\n",
    "# sometimes the second element has an extra \",\" that we should remove\n",
    "def remove_comma(str_list):\n",
    "    str_list[1] = str_list[1].replace(\",\", \"\")\n",
    "    return str_list\n",
    "\n",
    "cleaning_node = Node(Function(input_names=[\"str_list\"], \n",
    "                              output_names=[\"str_list_clean\"], \n",
    "                              function=remove_comma),\n",
    "                    name=\"cleaning\")\n",
    "\n",
    "\n",
    "# now we can extract year, month, day from our list and create ``datetime.datetim`` object\n",
    "def datetime_format(date_list):\n",
    "    import datetime\n",
    "    # year is always the last\n",
    "    year = int(date_list[2])\n",
    "    #day and month can be in the first or second position\n",
    "    # we can use datetime.datetime.strptime to convert name of the month to integer\n",
    "    try:\n",
    "        day = int(date_list[0])\n",
    "        month = datetime.datetime.strptime(date_list[1], \"%B\").month\n",
    "    except(ValueError):\n",
    "        day = int(date_list[1])\n",
    "        month = datetime.datetime.strptime(date_list[0], \"%B\").month\n",
    "    # and create datetime.datetime format\n",
    "    return datetime.datetime(year, month, day)\n",
    "\n",
    "\n",
    "datetime_node = Node(Function(input_names=[\"date_list\"], \n",
    "                                  output_names=[\"datetime\"], \n",
    "                              function=datetime_format),\n",
    "                    name=\"datetime\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# now we are ready to create JoinNode and sort the list of DOB\n",
    "\n",
    "def sorting_dob(datetime_list):\n",
    "    datetime_list.sort()\n",
    "    return datetime_list\n",
    "\n",
    "sorting_node = JoinNode(Function(input_names=[\"datetime_list\"], \n",
    "                              output_names=[\"dob_sorted\"], \n",
    "                              function=sorting_dob),\n",
    "                    joinsource=split_node, # this is the node that used iterables for x\n",
    "                    joinfield=['datetime_list'],\n",
    "                    name=\"sorting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# and we're ready to create workflow\n",
    "\n",
    "ex1_wf = Workflow(name=\"sorting_dob\")\n",
    "ex1_wf.connect(split_node, \"split_list\", cleaning_node, \"str_list\")\n",
    "ex1_wf.connect(cleaning_node, \"str_list_clean\", datetime_node, \"date_list\")\n",
    "ex1_wf.connect(datetime_node, \"datetime\", sorting_node, \"datetime_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# you can check the graph\n",
    "from IPython.display import Image\n",
    "ex1_wf.write_graph(graph2use='exec')\n",
    "Image(filename='graph_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# and run the workflow\n",
    "ex1_res = ex1_wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# you can check list of all nodes\n",
    "ex1_res.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# and check the results from sorting_dob.sorting\n",
    "list(ex1_res.nodes())[0].result.outputs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
