{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification for 1st-Level fMRI Analysis\n",
    "\n",
    "Nipype provides also an interfaces to create a first level Model for an fMRI analysis. Such a model is needed to specify the study-specific information, such as **condition**, their **onsets**, and **durations**. For more information, make sure to check out [nipype.algorithms.modelgen](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.algorithms.modelgen.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General purpose model specification\n",
    "\n",
    "The `SpecifyModel` provides a generic mechanism for model specification. A mandatory input called `subject_info` provides paradigm specification for each run corresponding to a subject. This has to be in the form of a `Bunch` or a list of `Bunch` objects (one for each run). Each `Bunch` object contains the following attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required for most designs\n",
    "\n",
    "- **`conditions`** : list of names\n",
    "\n",
    "\n",
    "- **`onsets`** : lists of onsets corresponding to each condition\n",
    "\n",
    "\n",
    "- **`durations`** : lists of durations corresponding to each condition. Should be left to a single 0 if all events are being modeled as impulses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "- **`regressor_names`**: list of names corresponding to each column. Should be None if  automatically assigned.\n",
    "\n",
    "\n",
    "- **`regressors`**: list of lists. values for each regressor - must correspond to the number of volumes in the functional run\n",
    "\n",
    "\n",
    "- **`amplitudes`**: lists of amplitudes for each event. This will be ignored by SPM's Level1Design.\n",
    "\n",
    "\n",
    "The following two (`tmod`, `pmod`) will be ignored by any `Level1Design` class other than `SPM`:\n",
    "\n",
    "- **`tmod`**: lists of conditions that should be temporally modulated. Should default to None if not being used.\n",
    "\n",
    "- **`pmod`**: list of Bunch corresponding to conditions\n",
    "   - `name`: name of parametric modulator\n",
    "   - `param`: values of the modulator\n",
    "   - `poly`: degree of modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with this information, one needs to specify:\n",
    "\n",
    "- whether the durations and event onsets are specified in terms of scan volumes or secs.\n",
    "\n",
    "- the high-pass filter cutoff,\n",
    "\n",
    "- the repetition time per scan\n",
    "\n",
    "- functional data files corresponding to each run.\n",
    "\n",
    "Optionally you can specify realignment parameters, outlier indices. Outlier files should contain a list of numbers, one per row indicating which scans should not be included in the analysis. The numbers are 0-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "An example Bunch definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import Bunch\n",
    "condnames = ['Tapping', 'Speaking', 'Yawning']\n",
    "event_onsets = [[0, 10, 50],\n",
    "                [20, 60, 80],\n",
    "                [30, 40, 70]]\n",
    "durations = [[0],[0],[0]]\n",
    "\n",
    "subject_info = Bunch(conditions=condnames,\n",
    "                     onsets = event_onsets,\n",
    "                     durations = durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input via textfile\n",
    "\n",
    "Alternatively, you can provide condition, onset, duration and amplitude\n",
    "information through event files. The event files have to be in 1, 2 or 3\n",
    "column format with the columns corresponding to Onsets, Durations and\n",
    "Amplitudes and they have to have the name event_name.run<anything else>\n",
    "e.g.: `Words.run001.txt`.\n",
    "    \n",
    "The event_name part will be used to create the condition names. `Words.run001.txt` may look like:\n",
    "\n",
    "    # Word Onsets Durations\n",
    "    0   10\n",
    "    20   10\n",
    "    ...\n",
    "\n",
    "or with amplitudes:\n",
    "\n",
    "    # Word Onsets Durations Amplitudes\n",
    "    0    10     1\n",
    "    20   10    1\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example based on dataset\n",
    "\n",
    "Now  let's look at a TSV file from our tutorial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /data/ds000114/task-fingerfootlips_events.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use [pandas](http://pandas.pydata.org/) to create a data frame from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trialinfo = pd.read_table('/data/ds000114/task-fingerfootlips_events.tsv')\n",
    "trialinfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the onsets, we first need to split them into the three conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in trialinfo.groupby('trial_type'):\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we now need to to is to put this into a ``Bunch`` object and we're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import Bunch\n",
    "\n",
    "conditions = []\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for group in trialinfo.groupby('trial_type'):\n",
    "    conditions.append(group[0])\n",
    "    onsets.append(group[1].onset.tolist())\n",
    "    durations.append(group[1].duration.tolist())\n",
    "\n",
    "subject_info = Bunch(conditions=conditions,\n",
    "                     onsets=onsets,\n",
    "                     durations=durations)\n",
    "subject_info.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse model specification\n",
    "\n",
    "In addition to standard models, `SpecifySparseModel` allows model generation for sparse and sparse-clustered acquisition experiments. Details of the model generation and utility are provided in [Ghosh et al. (2009) OHBM 2009](https://www.researchgate.net/publication/242810827_Incorporating_hemodynamic_response_functions_to_improve_analysis_models_for_sparse-acquisition_experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
