{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Execution Plugins\n",
    "\n",
    "As you learned in the [Workflow](basic_workflow.ipynb) tutorial, a workflow is executed with the ``run`` method. For example:\n",
    "\n",
    "    workflow.run()\n",
    "\n",
    "Whenever you execute a workflow like this, it will be executed in serial order. This means that no node will be executed in parallel, even if they are completely independent of each other. Now, while this might be preferable under certain circumstances, we usually want to executed workflows in parallel. For this, Nipype provides many different plugins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Local execution\n",
    "\n",
    "### ``Linear`` Plugin\n",
    "\n",
    "If you want to run your workflow in a linear fashion, just use the following code:\n",
    "\n",
    "    workflow.run(plugin='Linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ``MultiProc`` Plugin\n",
    "\n",
    "The easiest way to executed a workflow locally in parallel is the ``MultiProc`` plugin:\n",
    "\n",
    "    workflow.run(plugin='MultiProc', plugin_args={'n_procs': 4})\n",
    "\n",
    "The additional plugin argument ``n_procs``, specifies how many cores should be used for the parallel execution. In this case, it's 4.\n",
    "\n",
    "The `MultiProc` plugin uses the [multiprocessing](http://docs.python.org/library/multiprocessing.html) package in the standard library, and is the only parallel plugin that is guaranteed to work right out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cluster execution\n",
    "\n",
    "There are many different plugins to run Nipype on a cluster, such as: ``PBS``, ``SGE``, ``LSF``, ``Condor`` and ``IPython``. Implementing them is as easy as ``'MultiProc'``.\n",
    "\n",
    "    workflow.run('PBS', plugin_args={'qsub_args': '-q many'})\n",
    "    workflow.run('SGE', plugin_args={'qsub_args': '-q many'})\n",
    "    workflow.run('LSF', plugin_args={'qsub_args': '-q many'})\n",
    "    workflow.run('Condor')\n",
    "    workflow.run('IPython')\n",
    "    \n",
    "    workflow.run('PBSGraph', plugin_args={'qsub_args': '-q many'})\n",
    "    workflow.run('SGEGraph', plugin_args={'qsub_args': '-q many'})\n",
    "    workflow.run('CondorDAGMan')\n",
    "\n",
    "For a complete list and explanation of all supported plugins, see: http://nipype.readthedocs.io/en/latest/users/plugins.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
