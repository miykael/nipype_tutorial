{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Output\n",
    "\n",
    "Similarly important to data input is data output. Using a data output module allows you to restructure and rename computed output and to spatially differentiate relevant output files from the temporary computed intermediate files in the working directory. Nipype provides the following modules to handle data stream output:\n",
    "\n",
    "    DataSink\n",
    "    JSONFileSink\n",
    "    MySQLSink\n",
    "    SQLiteSink\n",
    "    XNATSink\n",
    "\n",
    "This tutorial covers only `DataSink`. For the rest, see the section [``interfaces.io``](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html) on the official homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSink\n",
    "\n",
    "A workflow working directory is like a **cache**. It contains not only the outputs of various processing stages, it also contains various extraneous information such as execution reports, hashfiles determining the input state of processes. All of this is embedded in a hierarchical structure that reflects the iterables that have been used in the workflow. This makes navigating the working directory a not so pleasant experience. And typically the user is interested in preserving only a small percentage of these outputs. The [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) interface can be used to extract components from this `cache` and store it at a different location. For XNAT-based storage, see [XNATSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#nipype-interfaces-io-xnatsink).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Unlike other interfaces, a [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink)'s inputs are defined and created by using the workflow connect statement. Currently disconnecting an input from the [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) does not remove that connection port.\n",
    "</div>\n",
    "\n",
    "Let's assume we have the following workflow.\n",
    "\n",
    "<img src=\"../static/images/datasink_flow.png\" width=\"160\">\n",
    "\n",
    "The following code segment defines the [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) node and sets the `base_directory` in which all outputs will be stored. The `container` input creates a subdirectory within the `base_directory`. If you are iterating a workflow over subjects, it may be useful to save it within a folder with the subject id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "datasink.inputs.base_directory = '/path/to/output'\n",
    "workflow.connect(inputnode, 'subject_id', datasink, 'container')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to save the realigned files and the realignment parameters to the same place the most intuitive option would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "workflow.connect(realigner, 'realigned_files', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this will not work as only one connection is allowed per input port. So we need to create a second port. We can store the files in a separate folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "workflow.connect(realigner, 'realigned_files', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion.par')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The period (.) indicates that a subfolder called par should be created. But if we wanted to store it in the same folder as the realigned files, we would use the `.@` syntax. The @ tells the [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) interface to not create the subfolder. This will allow us to create different named input ports for [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) and allow the user to store the files in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "workflow.connect(realigner, 'realigned_files', datasink, 'motion')\n",
    "workflow.connect(realigner, 'realignment_parameters', datasink, 'motion.@par')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for the input port of [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) takes the following form:\n",
    "\n",
    "    string[[.[@]]string[[.[@]]string] ...]\n",
    "    where parts between paired [] are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapNode\n",
    "\n",
    "In order to use [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) inside a MapNode, its inputs have to be defined inside the constructor using the `infields` keyword arg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization\n",
    "\n",
    "As discussed in [Iterables](basic_iteration.ipynb), one can run a workflow iterating over various inputs using the iterables attribute of nodes. This means that a given workflow can have multiple outputs depending on how many iterables are there. Iterables create working directory subfolders such as `_iterable_name_value`.  The `parameterization` input parameter controls whether the data stored using [DataSink](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html#datasink) is in a folder structure that contains this iterable information or not. It is generally recommended to set this to `True` when using multiple nested iterables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitutions\n",
    "\n",
    "The ``substitutions`` and ``regexp_substitutions`` inputs allow users to modify the output destination path and name of a file. Substitutions are a list of 2-tuples and are carried out in the order in which they were entered. Assuming that the output path of a file is:\n",
    "\n",
    "    /root/container/_variable_1/file_subject_realigned.nii\n",
    "\n",
    "we can use substitutions to clean up the output path.\n",
    "\n",
    "```python\n",
    "datasink.inputs.substitutions = [('_variable', 'variable'),\n",
    "                                 ('file_subject_', '')]\n",
    "```\n",
    "\n",
    "This will rewrite the file as:\n",
    "\n",
    "    /root/container/variable_1/realigned.nii\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Note**: In order to figure out which substitutions are needed it is often useful to run the workflow on a limited set of iterables and then determine the substitutions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realistic Example\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before we can use `DataSink` we first need to run a workflow. For this purpose, let's create a very short preprocessing workflow that realigns and smooths one functional image of one subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a `SelectFiles` node. For an explanation of this step, see the [Data Input](basic_data_input.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# Create SelectFiles node\n",
    "templates={'func': '{subject}/{session}/func/{subject}_{session}_task-fingerfootlips_bold.nii.gz'}\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "sf.inputs.subject = 'sub-01'\n",
    "sf.inputs.session = 'ses-test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let's create the motion correction and smoothing node. For an explanation about this step, see the [Nodes](basic_nodes.ipynb) and [Interfaces](basic_interfaces.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import MCFLIRT, IsotropicSmooth\n",
    "\n",
    "# Create Motion Correction Node\n",
    "mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                       save_plots=True),\n",
    "               name='mcflirt')\n",
    "\n",
    "# Create Smoothing node\n",
    "smooth = Node(IsotropicSmooth(fwhm=4),\n",
    "              name='smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, let's create the workflow that will contain those three nodes. For an explanation about this step, see the [Workflow](basic_workflow.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Workflow\n",
    "from os.path import abspath\n",
    "\n",
    "# Create a preprocessing workflow\n",
    "wf = Workflow(name=\"preprocWF\")\n",
    "wf.base_dir = '/output/working_dir'\n",
    "\n",
    "# Connect the three nodes to each other\n",
    "wf.connect([(sf, mcflirt, [(\"func\", \"in_file\")]),\n",
    "            (mcflirt, smooth, [(\"out_file\", \"in_file\")])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, let's run the preprocessing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the execution of the workflow we have all the data hidden in the working directory `'working_dir'`. Let's take a closer look at the content of this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree /output/working_dir/preprocWF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is way too much content that we might not really care about. To relocate and rename all the files that are relevant to you, you can use `DataSink`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use `DataSink`\n",
    "\n",
    "`DataSink` is Nipype's standard output module to restructure your output files. It allows you to relocate and rename files that you deem relevant.\n",
    "\n",
    "Based on the preprocessing pipeline above, let's say we want to keep the smoothed functional images as well as the motion correction parameters. To do this, we first need to create the `DataSink` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink\n",
    "\n",
    "# Create DataSink object\n",
    "sinker = Node(DataSink(), name='sinker')\n",
    "\n",
    "# Name of the output folder\n",
    "sinker.inputs.base_directory = '/output/working_dir/preprocWF_output'\n",
    "\n",
    "# Connect DataSink with the relevant nodes\n",
    "wf.connect([(smooth, sinker, [('out_file', 'in_file')]),\n",
    "            (mcflirt, sinker, [('mean_img', 'mean_img'),\n",
    "                               ('par_file', 'par_file')]),\n",
    "            ])\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the `output` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree /output/working_dir/preprocWF_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks nice. It is what we asked it to do. But having a specific output folder for each individual output file might be suboptimal. So let's change the code above to save the output in one folder, which we will call `'preproc'`.\n",
    "\n",
    "For this we can use the same code as above. We only have to change the connection part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.connect([(smooth, sinker, [('out_file', 'preproc.@in_file')]),\n",
    "            (mcflirt, sinker, [('mean_img', 'preproc.@mean_img'),\n",
    "                               ('par_file', 'preproc.@par_file')]),\n",
    "            ])\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the new output folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree /output/working_dir/preprocWF_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already much better. But what if you want to rename the output files to represent something a bit more readable. For this `DataSink` has the `substitution` input field.\n",
    "\n",
    "For example, let's assume we want to get rid of the string `'task-fingerfootlips'` and `'bold_mcf'` and that we want to rename the mean file, as well as adapt the file ending of the motion parameter file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define substitution strings\n",
    "substitutions = [('_task-fingerfootlips', ''),\n",
    "                 (\"_ses-test\", \"\"),\n",
    "                 ('_bold_mcf', ''),\n",
    "                 ('.nii.gz_mean_reg', '_mean'),\n",
    "                 ('.nii.gz.par', '.par')]\n",
    "\n",
    "# Feed the substitution strings to the DataSink node\n",
    "sinker.inputs.substitutions = substitutions\n",
    "\n",
    "# Run the workflow again with the substitutions in place\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a final look at the output folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree /output/working_dir/preprocWF_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, much clearer filenames!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Create a simple workflow for skullstriping with FSL, the first node should use `BET` interface and the second node will be a ``DataSink``. Test two methods of connecting the nodes and check the content of the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from nipype import Node, Workflow\n",
    "from nipype.interfaces.io import DataSink\n",
    "from nipype.interfaces.fsl import BET\n",
    "\n",
    "# Skullstrip process\n",
    "ex1_skullstrip = Node(BET(mask=True), name=\"ex1_skullstrip\")\n",
    "ex1_skullstrip.inputs.in_file = \"/data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Create DataSink node\n",
    "ex1_sinker = Node(DataSink(), name='ex1_sinker')\n",
    "ex1_sinker.inputs.base_directory = '/output/working_dir/ex1_output'\n",
    "\n",
    "# and a workflow\n",
    "ex1_wf = Workflow(name=\"ex1\", base_dir = '/output/working_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# let's try the first method of connecting the BET node to the DataSink node\n",
    "ex1_wf.connect([(ex1_skullstrip, ex1_sinker, [('mask_file', 'mask_file'),\n",
    "                                              ('out_file', 'out_file')]),\n",
    "            ])\n",
    "ex1_wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# and we can check our sinker directory\n",
    "! tree /output/working_dir/ex1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# now we can try the other method of connecting the node to DataSink\n",
    "ex1_wf.connect([(ex1_skullstrip, ex1_sinker, [('mask_file', 'bet.@mask_file'),\n",
    "                                              ('out_file', 'bet.@out_file')]),\n",
    "            ])\n",
    "ex1_wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# and check the content of the output directory (you should see a new `bet` subdirectory with both files)\n",
    "! tree /output/working_dir/ex1_output"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
