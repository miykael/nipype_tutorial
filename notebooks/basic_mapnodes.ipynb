{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "# MapNode\n",
    "\n",
    "If you want to iterate over a list of inputs, but need to feed all iterated outputs afterwards as one input (an array) to the next node, you need to use a **``MapNode``**. A ``MapNode`` is quite similar to a normal ``Node``, but it can take a list of inputs and operate over each input separately, ultimately returning a list of outputs. (The main homepage has a [nice section](http://nipype.readthedocs.io/en/latest/users/mapnode_and_iterables.html) about ``MapNode`` and ``iterables`` if you want to learn more).\n",
    "\n",
    "Let's demonstrate this with a simple function interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype import Function\n",
    "def square_func(x):\n",
    "    return x ** 2\n",
    "square = Function([\"x\"], [\"f_x\"], square_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this function just takes a numeric input and returns its squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square.run(x=2).outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to square a list of numbers? We could set an iterable and just split up the workflow in multiple sub-workflows. But say we were making a simple workflow that squared a list of numbers and then summed them. The sum node would expect a list, but using an iterable would make a bunch of sum nodes, and each would get one number from the list. The solution here is to use a `MapNode`.\n",
    "\n",
    "The `MapNode` constructor has a field called `iterfield`, which tells it what inputs should be expecting a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype import MapNode\n",
    "square_node = MapNode(square, name=\"square\", iterfield=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170730-12:58:10,179 workflow INFO:\n",
      "\t Executing node square in dir: /tmp/tmpeo5f95vk/square\n",
      "170730-12:58:10,185 workflow INFO:\n",
      "\t Executing node _square0 in dir: /tmp/tmpeo5f95vk/square/mapflow/_square0\n",
      "170730-12:58:10,193 workflow INFO:\n",
      "\t Executing node _square1 in dir: /tmp/tmpeo5f95vk/square/mapflow/_square1\n",
      "170730-12:58:10,200 workflow INFO:\n",
      "\t Executing node _square2 in dir: /tmp/tmpeo5f95vk/square/mapflow/_square2\n",
      "170730-12:58:10,206 workflow INFO:\n",
      "\t Executing node _square3 in dir: /tmp/tmpeo5f95vk/square/mapflow/_square3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_node.inputs.x = [0, 1, 2, 3]\n",
    "square_node.run().outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `iterfield` can take a list of names, you can operate over multiple sets of data, as long as they're the same length. The values in each list will be paired; it does not compute a combinatoric product of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power_func(x, y):\n",
    "    return x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170730-12:58:11,582 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmp_adgsic6/power\n",
      "170730-12:58:11,587 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmp_adgsic6/power/mapflow/_power0\n",
      "170730-12:58:11,593 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmp_adgsic6/power/mapflow/_power1\n",
      "170730-12:58:11,600 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmp_adgsic6/power/mapflow/_power2\n",
      "170730-12:58:11,606 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmp_adgsic6/power/mapflow/_power3\n",
      "[1, 1, 4, 27]\n"
     ]
    }
   ],
   "source": [
    "power = Function([\"x\", \"y\"], [\"f_xy\"], power_func)\n",
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\", \"y\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = [0, 1, 2, 3]\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not every input needs to be an iterfield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170730-12:58:12,732 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmphi04u46v/power\n",
      "170730-12:58:12,737 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmphi04u46v/power/mapflow/_power0\n",
      "170730-12:58:12,744 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmphi04u46v/power/mapflow/_power1\n",
      "170730-12:58:12,750 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmphi04u46v/power/mapflow/_power2\n",
      "170730-12:58:12,756 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmphi04u46v/power/mapflow/_power3\n",
      "[0, 1, 8, 27]\n"
     ]
    }
   ],
   "source": [
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = 3\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of `iterables`, each underlying `MapNode` execution can happen in **parallel**. Hopefully, you see how these tools allow you to write flexible, reusable workflows that will help you processes large amounts of data efficiently and reproducibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is this important?\n",
    "\n",
    "Let's consider we have multiple functional images (A) and each of them should be motioned corrected (B1, B2, B3,..). But afterwards, we want to put them all together into a GLM, i.e. the input for the GLM should be an array of [B1, B2, B3, ...]. [Iterables](basic_iteration.ipynb) can't do that. They would split up the pipeline. Therefore, we need **MapNodes**.\n",
    "\n",
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "Let's look at a simple example, where we want to motion correct two functional images. For this we need two nodes:\n",
    " - Gunzip, to unzip the files (plural)\n",
    " - Realign, to do the motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm import Realign\n",
    "from nipype.pipeline.engine import Node, MapNode, Workflow\n",
    "\n",
    "files = ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz',\n",
    "         '/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz']\n",
    "\n",
    "realign = Node(Realign(register_to_mean=True),\n",
    "               name='motion_correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to specify the input for the **Gunzip** node with a simple **Node**, we get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz'] <class 'list'> was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4c705ede4d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgunzip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGunzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gunzip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgunzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/nipype/interfaces/traits_extension.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0;34m'fast validator'\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mvalidated_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidated_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/traits/trait_types.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_editor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/traits/trait_handlers.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m    171\u001b[0m         raise TraitError( object, name, self.full_info( object, name, value ),\n\u001b[0;32m--> 172\u001b[0;31m                           value )\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_info\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTraitError\u001b[0m: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz'] <class 'list'> was specified."
     ]
    }
   ],
   "source": [
    "gunzip = Node(Gunzip(), name='gunzip',)\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "TraitError: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz'] <type 'list'> was specified.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we do it with a **MapNode**, it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gunzip = MapNode(Gunzip(), name='gunzip',\n",
    "                 iterfield=['in_file'])\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just have to create a workflow, connect the nodes and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170730-12:58:25,161 workflow INFO:\n",
      "\t Workflow realign_with_spm settings: ['check', 'execution', 'logging']\n",
      "170730-12:58:25,200 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170730-12:58:25,206 workflow INFO:\n",
      "\t Executing: gunzip ID: 0\n",
      "170730-12:58:25,224 workflow INFO:\n",
      "\t Adding 2 jobs for mapnode gunzip\n",
      "170730-12:58:25,232 workflow INFO:\n",
      "\t Executing: _gunzip0 ID: 2\n",
      "170730-12:58:25,243 workflow INFO:\n",
      "\t Executing: _gunzip1 ID: 3\n",
      "170730-12:58:25,246 workflow INFO:\n",
      "\t Executing node _gunzip0 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip0\n",
      "170730-12:58:25,259 workflow INFO:\n",
      "\t Executing node _gunzip1 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip1\n",
      "170730-12:58:26,824 workflow INFO:\n",
      "\t [Job finished] jobname: _gunzip0 jobid: 2\n",
      "170730-12:58:27,40 workflow INFO:\n",
      "\t [Job finished] jobname: _gunzip1 jobid: 3\n",
      "170730-12:58:27,43 workflow INFO:\n",
      "\t Executing: gunzip ID: 0\n",
      "170730-12:58:27,67 workflow INFO:\n",
      "\t Executing node gunzip in dir: /output/realign_with_spm/gunzip\n",
      "170730-12:58:27,109 workflow INFO:\n",
      "\t Executing node _gunzip0 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip0\n",
      "170730-12:58:27,123 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170730-12:58:27,137 workflow INFO:\n",
      "\t Executing node _gunzip1 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip1\n",
      "170730-12:58:27,153 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170730-12:58:27,177 workflow INFO:\n",
      "\t [Job finished] jobname: gunzip jobid: 0\n",
      "170730-12:58:27,181 workflow INFO:\n",
      "\t Executing: motion_correction ID: 1\n",
      "170730-12:58:27,202 workflow INFO:\n",
      "\t Executing node motion_correction in dir: /output/realign_with_spm/motion_correction\n",
      "170730-13:00:53,418 workflow INFO:\n",
      "\t [Job finished] jobname: motion_correction jobid: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fc72229ef98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcflow = Workflow(name='realign_with_spm')\n",
    "mcflow.connect(gunzip, 'out_file', realign, 'in_files')\n",
    "mcflow.base_dir = '/output'\n",
    "mcflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
